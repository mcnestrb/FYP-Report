% Created 2017-05-01 Mon 23:08
% Intended LaTeX compiler: xelatex
\documentclass[a4paper, notitlepage]{report}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\include{settings/preamble}
\addbibresource{bibliography.bib}
\author{Brian McNestry}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={Brian McNestry},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 24.5.1 (Org mode 9.0.5)}, 
 pdflang={English}}
\begin{document}

\inserttitlepage

\pagenumbering{roman}

\declaration

\permissiontolend

\insertabstract

\acknowledgements

\tableofcontents

\newpage

\pagenumbering{arabic}

\part{Introduction}
\label{sec:org369f62a}
Currently in the field of smart grid technologies, there is an abundance of
theoretical approaches to the problems of managing the transactions between
consumers and suppliers of energy \cite{ambrosio2016transactive}. While there are
multiple facets to this problem, this project examines the problem of matching
supply and demand in the face of unpredictable supply. The world is slowly
moving towards a future in which renewable energy sources will become our
primary method of energy production, particularly with the inevitable depletion
of fossil fuels \cite{boyle1997renewable}. This future, which will unfortunately be accompanied by a more
unpredictable supply of energy, will require a smarter approach to the
accumulation and distribution of energy. Due to the proliferation of decision
making computers, the smart grid is a very popular solution. As mentioned
previously,  research has been conducted by hundreds of papers on theoretical
solutions to this problem. However very few have real implementations and do not
take into account the limitations and overheads of a real network. 

The goal of this project is to implement a network solution to the problem of
matching supply and demand in the face of unpredictable supply. The paper
authored by Wayes Tushar \cite{tushar2014prioritizing} formed the basis of the
project and therefore this report. The system will then be compared against a
simple scenario of the current REFIT scheme \cite{lauber2004refit} and an analysis will be provided to
see whether or not this particular smart grid solution would be effective in a
real world situation. 

First a discussion of the technologies used and an explanation of the associated
terms will be presented, including topics such as the smart grid, the current
implementation of managing supply (REFIT), definitions of auctions and game
theory, as well as a brief summary of the mathematical optimisation techniques
employed in this project. Next, the design of the project will be examined and
finally the actual implementation itself will be presented. To conclude there
will be an assessment of the system designed and a number of potential
continuations of the project will be discussed.
\part{Background}
\label{sec:orgb50eddd}
\chapter{Decentralised Grid}
\label{sec:orgb4c1db9}
At present, in Ireland and in many other countries, the national electric grid
infrastructure is controlled by a central body, namely the ESB. While there are
several electricity providers in Ireland, such as Bord Gáis Energy, SSE
Airtricity and Energy Ireland, each of them use the same distribution network.
Fundamentally, the power is provided from each of the different providers and
then routed into the same centralised hub belonging to the ESB. From there, each
consumer (a household) receives the energy that they pay for accordingly at a
fixed rate through that same infrastructure belonging to the ESB. This is
similar to many other countries where there is a centralised grid.

This system has been in place for decades and lends itself very well to large
companies can providing a steady supply of energy by way of electricity plants
that use both renewable and nonrenewable energy sources. Non-renewable energy
sources, also known as fossil fuels, include resources such as coal, gas and
oil. While these are finite resources, at present they can be burned at a steady
rate in order to meet the demands of customers. Electricity from renewable
sources can also be produced at a reasonably steady rate by placing large farms
in areas that are particularly well suited to the type of renewable energy being
produced. For example, large wind farms are set up in windy regions far removed
from residential or urban areas and solar panels can be placed in regions that
typically enjoy clearer skies than other areas.

However in the future, with the ongoing depletion of nonrenewable resources,
increasing numbers of customers will turn to erecting solar panels and local
wind farms  on their own properties, regardless of whether or not they are
living in a particularly sunny or windy area. Presently there are a few houses
that use a solar panel to heat their water or other smaller tasks but soon more
and more people will become more and more dependent on what they can produce
either within their own home, or in a more collective sense in their own
neighbourhood to power their houses \cite{apergis2010renewable}.

The issue that then arises in these areas that aren’t as sunny or windy is that
supply of electricity is no longer steady. The current system could not be
maintained as the energy produced on a local level would be small enough that it
would not be worth passing this energy upstream to the central grid. The energy
would instead be used at a local level to try to cover the demand for
electricity of the house or business with which that particular device is
associated.

The model of infrastructure that would then be required is that of a
decentralised grid. This model would require a massive infrastructure overhaul
in order to implement, so it would not exist until it is absolutely necessary
and has been accepted by the major companies who would then go about
implementing it. The rough idea of a distributed grid is described in figure
1.1. Throughout the rest of this report the phrases “distributed grid” and
“decentralised grid” are used interchangeably.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/DecentralisedGrid.jpg}
\caption{\label{fig:orgce80043}
Each local consumer and supplier is attached to a regional grid hub which manages the allocation of electricity between suppliers and consumers. This is just a simple overview of the idea but conceivably a consumer or a supplier could be connected to two or more different regional grid hubs.}
\end{figure}
\chapter{Smart Grid}
\label{sec:orgb1e8b7d}
\section{Overview}
\label{sec:orgcbe0077}
Due to advancements in networking technologies, and the field of sophisticated
decision making technologies, the idea of a smart grid has become increasingly
popular. Actors within a smart grid, be they individual consumers or suppliers,
or groups thereof, can be fitted with small computers that perceive changes in
the grid and then these actors can react accordingly. Several different types of
management systems have been constructed in order to successfully, fairly and
efficiently allocate resources for each of these different types of actors. The
two primary types of management systems that were examined as part of this final
year project were Auctions and Game Theory which will both be discussed in
detail later on. 

The smart grid is not only used in this manner, but has many other potential
applications, some of which have been implemented already in several cities and
regions throughout the world. These applications include energy consumption or
production prediction, scheduling the use of consumers in order to reduce costs
of operation, and smart reaction to disruptions or blackouts within the grid to
reduce the damage that occurs as a result. 

In this project it is assumed that the consumers within the system are outfitted
with some kind of prediction technology. An example of such a system has been
proposed by Garcia et al \cite{mohsenian2010optimal} where a device tries to time
its own operation within a certain time-frame in accordance with when the price
of energy is cheapest. It also attempts to predict how much energy the system
will consume based off its own knowledge of previous experiences in buying power
at that particular time of day, allowing the system to learn over time and make
smarter decisions as time goes on. 
\section{Microgrids and Nanogrids}
\label{sec:org871f9b0}
At present smart grids have generally been implemented at the level of
microgrids. Microgrids are generally thought of having a consumer be a single
house, or perhaps a group of houses, and a supplier being a small wind farm or
solar farm, or perhaps a group of these together. In the case of a microgrid,
actors within the system are defined in similar terms to those involved in a
centralised grid system, meaning that the transition from a centralised grid to
the microgrid scheme is a relatively easy one.

An example of a real world implementation is that of the system in place in
Japan. The majority of the work completed on this system was conducted following
the disaster of Fukushima, where it became clear that a reliance on a single
power source and a centralised power distribution network left the country
vulnerable following the disaster \cite{japan_microgrids}. Several regions were
cut off from power as a result of the disaster which hampered relief efforts as
well as making the lives of ordinary Japanese citizens more difficult. Had a
microgrid system been in place then fewer hospitals and homes would have been
left without power following the disaster.

The company ENEL has also introduced a smart grid system in the region of Apulia
in southern Italy \cite{sapienza2013enel} with great success. The system there
allows customers to produce and network their own electricity as well as making
them more aware of their consumption and any potential savings.

The nanogrid system is very similar to that of the microgrid system conceptually
but is concerned with a much smaller scale. A nanogrid is one that operates
within the confines of a single building, generally where each consumer is a
single appliance such as a washing machine or an electronic vehicles (EV).
Suppliers would also be very small scale perhaps a set of solar panels or a
small wind turbine. A nanogrid system could also be adapted to aggregate a
number of devices to act as one as a single actor within the nanogrid system,
for example all the lights on one floor of a house could act as a single
consumer and draw on a shared reserve of power.

Another extension would be to incorporate a nanogrid system as a sub-node of a
microgrid. This would create a hierarchy of distributed grids. This tree could
also be adapted into a graph where a parent node in the tree could have multiple
children and a child could have multiple parents. This will be discussed more in
the conclusion.
\chapter{REFIT Scheme}
\label{sec:orgc288a05}
The REFIT scheme (Renewable Energy Feed In Tariff) is one of the most common
ways in which countries around the world, including Germany, Spain and the state
of Hawaii \cite{couture2010analysis}, try to incentivise renewable energy sources
and suppliers to sell energy into the main grid for consumption by consumers.
The primary tenet of the REFIT scheme is to guarantee a fixed price for energy
provided by suppliers at particular times of the day. These prices are offered
in a non-discriminatory fashion for every kWh produced by the supplier. The
prices can be lower or higher based on the type of energy being produced. For
example in Germany the price is higher for suppliers of solar energy than for
suppliers of wind energy, according to the EU at the time of the writing of this
report \cite{refit_germany}.

The main advantage of this type of a scheme is that firstly it incentivises
companies to invest in renewable energy because they know they’ll receive a good
return on their investment. It also incentivises landowners and homeowners to
invest, thereby creating a large infrastructure of renewable energy resources in
a relatively small space of time and this has worked effectively in Germany
\cite{lauber2004refit}. The payment also easily covers the cost of creating the
solar panels or wind turbines for regular consumers.

The main downside to the REFIT scheme however is that because it provides a
fixed amount based primarily on the type of energy produced and for how long it
is being provided, which means that it is not worth it for a supplier to sell if
it has a poor supply in reserve for example. In this case, the incentive to sell
energy is quite low as selling any energy would drain the supplier of most of
its power. Therefore a scheme involving a dynamic price model that incentivises
all suppliers at all times to contribute to the demand and maximise their own
utility in the system might be better. 
\chapter{Auctions}
\label{sec:org365ee07}
\section{Overview}
\label{sec:orge001274}
The first type of node management systems considered as part of this project was
that of auctions. Auctions generally have a number of different types of
properties and as such, can be classified into different groupings. 

\begin{itemize}
\item Single- or multi-dimensional
\item One- or two-sided
\item Open-cry or sealed-bid
\item First- or k th-price
\item Single- or multi-unit
\item Single- or multi-item
\end{itemize}

While all of these are examined in detail in the book by Simon Parsons
\cite{parsons2011auctions}, only one of these will be discussed here as it the
only type of auction that was considered. The reasoning for the decision as to
why this was the only type considered is also explained. The type of auction
investigated was a continuous double auction. 
\section{Continuous Double Auction}
\label{sec:org5fd5bbb}
A continuous double auction was discussed in the paper by Ramachandran
\cite{ramachandran2011intelligent} among others and was therefore a popular
candidate by several potential energy management systems. The idea of a double
auction is a simple one. Instead of trying to match multiple bidders to a single
seller or multiple sellers to a single buyer, a double auction is where there
are multiple sellers and multiple bidders. Through combining the buy-side and
the sell-side of an auction into a single process, we then have a two-sided or
double action. 

A continuous double auction is an extension and a refinement of a double auction
where multiple rounds are conducted until as many bidders and sellers have been
satisfied as is possible. The first stage attempts to match up as many bidders
and sellers as possible who have compatible bids. After that both the sellers
and the bidders attempt to adjust their respective ask and bid prices and then
another round begins. This process continues iteratively until either all actors
involved in the auction are satisfied or until all remaining actors have reached
their respective buying or selling thresholds. 

The reason why this particular style of auction was chosen to be investigated
was that it matches the real world scenario of having multiple consumers within
a nanogrid environment as well as multiple suppliers. It is also reasonable to
assume that some kind of memory might be built into the consumers and suppliers
so that they might remember what each other offered on previous occasions and
submit bids in order to be accepted quicker. The iterative style of the
continuous auction was appealing and realistic due to the nature of managing the
bids and sales of so many different actors within one given system. Most of the
auctions investigated as part of this project required the central controller
having access to all the private information of all the other nodes. This, among
other reasons, led to auctions not being implemented for this project and this
will be discussed in further detail later.
\chapter{Game Theory}
\label{sec:orgbf3f5cb}
\section{Overview}
\label{sec:orge3ea004}
The field of game theory is one that has many different facets and versions
depending on the situation in which this is used. In this section the
nomenclature and jargon of game theory will be discussed, as will a short
explanation about the decision to select the type of game implemented as part of
this final year project. First the two main types of interactions between
players in a game will be discussed and after that the two primary types of
playing styles. However, before this, certain traits that are universal for any
type of game that must first be explained in order to grasp the concept of game
theory enough to understand some implementation decisions later in this report
to grasp the general concept of game theory itself.

In game theory, players within a game compete for a finite resource with the
objective of maximising their own utility within the scope of that game. Each
player within the game has an associated utility function that is generally the
same for all players within that game. The utility function generally results in
some scalar value which is trying to reach some maximum value, either on an
individual or collective level. There is generally some kind of manager node
also involved, which helps to conduct the game between all of the players
involved. Within any particular game, the players are all trying to maximise
their own utility. However in different types of games they may also be
conscious of the utilities of all the other players involved and try to react
accordingly, whether to further their own goal or to further the goals of the
collective group.

A well defined game has some form of state of equilibrium. This state of
equilibrium is when the sum of utilities of all the players within the game
reaches a maximum. The central managing node, if there is one, generally decides
whether or not this state has been reached. This state is the success state of
the game. In a well-designed game the utility function must be designed such
that the state of equilibrium, that is the success state, not only can be
reached but also that reaching that state is appealing to all players within the
game.
\section{Non-Cooperative Game Theory}
\label{sec:org0c581ca}
Non-Cooperative games are the simplest types of games both to understand and
design. The core component of a non-cooperative game is that all of the players
are operating purely independently while trying to maximise their own utility.
Each player within the game knows the best strategy to take in order to maximise
their own utility. Because every player in a game has the same objectives and
strategies available to them, each player knows what strategy will maximise its
own utility, based on everyone else trying the same technique

This is where the concept of equilibrium comes into play. Equilibrium is the
state in which there is the least disparity between the best player and the
worst player, that is that each player performs the best that it can with the
knowledge that all other players are similarly going to try to maximise their
own utilities. With this knowledge, each player is then able to pick the
strategy that maximises its own utility, taking into consideration that all
other players are trying to do the exact same thing and therefore it picks an
appropriate strategy. In a well designed game, there should also be no incentive
for a player to change their strategy to try to undercut other players. If made
correctly, such an action would have an adverse effect on the player in the
game. In this case all other players would then be aware that this player’s
strategy had changed and would then react accordingly in order to maximise their
own utility and decrease that player’s utility.
\section{Cooperative Game Theory}
\label{sec:org4c214dd}
Cooperative game theory shares many similar traits with that of non-cooperative
game theory as outlined in section 5.1. However the defining feature of
cooperative game theory is that players within the game will form coalitions
based on threats and incentives that occur between each other. The key component
of cooperative game theory is the analysis of which coalitions are likely to
form within any given game and what the projected outcomes are based upon these
permutations of coalitions. In this way the study of cooperative games have two
main facets. Firstly, they are concerned with what might cause different groups
of players to act together in unison. Secondly they are concerned with the most
likely outcomes of each of these games that happen when different groups form.

In this project, the nodes involved in the game are all of the energy suppliers
who are trying to maximise their own profit based on the amount of energy that
they are able to sell. The utility functions of the nodes and other details will
be discussed later in the Implementation section of this report. The desired
outcome of each player is therefore entirely selfish and because they are all
trying to compete for a finite price, they each want to obtain as much of that
money as possible. Therefore it does not follow to design this game in such a
way that these players should be able to form coalitions, as any coalition would
involve compromising and receiving less money which doesn’t make sense in this
game. Similarly due to the lack of communication between the players in the
game, they can also never know if other players could change their strategies so
are unable to even realise that cooperation is even possible at any given stage.
\section{Cournot and Stackelberg Games}
\label{sec:orgd352951}
Cournot and Stackelberg games are two manners in which players participate in
the game, in other words they constitute the structure of the game as opposed to
how players react to one another and strategise within the game. Both of these
are relatively easy concepts to understand so this section should be quite
short. Because these different structures of games affect the way in which a
player interacts with the other players in the game, different strategies can be
better or worse based on whether the game is a Cournot game or a Stackelberg
game and in some cases some strategies may not even be possible within different
game structures.

A Cournot game is simply where all the players make their moves at the same
time. For example, all players may submit their moves separately to a central
manager node who then reveals all of the different moves at the same time and
tries to work out and resolve all the different collisions and determine what
exactly the outcome of the game was on that particular turn. In a Cournot game,
the players all have to predict what the most likely turn of all the other
players are and react accordingly for every round of the game.

A Stackelberg game is where there is a leader within the game who plays first,
attempting to maximise its own utility first and then all other players in the
game play in turn after that and are able to see the moves of all other players
before them. Obviously in this kind of a game, where players are competing over
a finite resource, whoever plays first has an immediate advantage over the over
players in the game. This trickles down through the game, so that while any
given player has a disadvantage compared the whoever had the preceding turn,
they have a distinct advantage over all players who come afterwards.

The reasoning behind choosing a Stackelberg game over a Cournot game for this
project will be discussed later in the Implementation section of this report.
\chapter{Optimisation Techniques}
\label{sec:orga916600}
\section{Overview}
\label{sec:org3a7beec}
Optimisation techniques are an important part of the field of mathematics and
are reasonably simple to understand, but can be extremely difficult to
formulate. Optimisation problems concern themselves with a key problem that is
relevant to many different fields of engineering and computer programming.

For a function \(f \colon A \rightarrow \mathbb{R}^n\) for a particular set \(A\),
an optimisation problem is concerned with finding an element \(x_o\) of \(A\) where
\(f(x_o) <= f(x)\) for a minimisation problem or \(f(x_o) >= f(x)\) for a
maximisation problem, \(\forall x \in A\). These optimisation problems manifest
themselves in countless fields from economics \cite{dixit1990optimization}, civil
engineering \cite{piryonesi2017mathematical} and of course as part of the smart
grid \cite{ahat2013smart}. The optimisation techniques involved in this particular
project are used on each of the two utility functions involved in the process
namely that of each of the game players and then the moderator actor process
involved in the system. This will of course be discussed in more detail later on.

One of the main benefits of an optimisation technique is that it is often
obtainable using linear algebraic methods which means that a computer can figure
out the solution to the optimisation problem in polynomial time. Another benefit
of this is that an optimisation technique can be used in tandem with any other
problem solving technique in order to find a better solution much faster. If any
problem fits the parameters of the optimisation as defined above then different
optimisation techniques can be applied or at least the same one in multiple
places.

While the basic premise and motivation behind every optimisation technique is
the same, different types of sets of values can be used for the set \(A\) and as a
result. Fortunately, different types of optimisation techniques have been
developed in order to more efficiently solve problems in each of these areas. In
some cases, the type of values in the set such as in a convex set, actually make
other optimisation methods useless. In this project, two main optimisation
methods were used, namely Convex Optimisation and Hyperplane Projection
Optimisation. Both techniques are involved with quickly and accurately solving
for a maximum in the case of two different utility functions but operate with
different types of sets, each one being suitable for the relevant type of problem.
\section{Convex Optimisation}
\label{sec:org36e84b4}
Convex optimisation is defined as the solving of minimisation problems
that involve convex functions being applied to convex sets \cite{boyd2004convex}.
Due to the nature of the convexity of the sets involved in these sorts of
problems, a term that I will discuss momentarily, the local minimum that is
discovered is actually a global minimum. Basically this means that the curve of
the graphed outputs from mapping the values of a convex set through a convex
function, only has a single minimum as opposed to a situation where the curve
could have multiple minimums or values that can be converged on which are not
the true minimum of the curve. This property of a convex optimisation problem as
well as the property of general optimisation problems of being able to solve the
problem in polynomial time means that the true solution can be discovered
relatively quickly.

A convex set is simply a region in which, if you draw a line between any two
arbitrary points in the region, then all points on the line are also inside the
region as outlined in the left side of Fig 6.1. The right side shows a
non-convex set where there is a hollow section to the region.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/convex_set.png}
\caption{\label{fig:org566fd3d}
A convex set (gtMath March 2016) \cite{convex_set_img}}
\end{figure}

A convex function on the other hand is simply a function where the entire line
segment between any two points on the graph is above the or on the graph. This
is the part of convex optimisation that determines the fact that the local
minimum is a global minimum. Convex functions are extremely common in the field
of mathematics such as the quadratic function \(x^2\) and the exponential function
\(e^x\). 

Convex optimisation is therefore a relatively simple concept to understand and
is clearly seen to be a very useful and efficient method of accurately and
quickly finding solutions to minimisation problems.
\section{Hyperplane Projection}
\label{sec:orga2cc982}
\subsection{Variational Inequality Problem}
\label{sec:orgc9336e2}
The hyperplane projection method is a tool for solving problems that suit the
criteria of a variational inequality problem so first that must be explained
before moving onto the concept of the solution to such a problem.

A variational inequality is an inequality that involves a functional that must
be solved for all variables in a set, usually a convex set. As a side note,
although this problem also involves a convex set like the convex optimisation
problem, the functional is not a convex function and therefore convex
optimisation does not apply in this instance. A functional is a a function that
maps a vector space onto its underlying field of scalars. Often this vector
space can be a series of functions, meaning that the functional takes a function
as an argument and can be interpreted as a function of functions. This is
similar to the Haskell idea of higher order functions, where a single higher
order function can be used to operate on multiple functions and perhaps capture
some other important piece of data for a given system.

The origin of, and primary application of, variational inequality problems is in
the field of finding solutions of equilibrium in a given system. As we'll see
later on in the implementation section of this report, finding the state of Nash
Equilibrium between the different suppliers that take part in the game requires a
state of equilibrium. Therefore it can be easily inferred that the variational
inequality problem is applicable and the problem can be solved as such using a
method appropriate for such a problem.

The hyperplane projection method defined here also stipulates that the
underlying functional involved in the problem must meet a certain monotonicity
criteria. Monotonicity is a property of a function that says that the function
must either be non-decreasing or non-increasing. The function does not have to
be constantly increasing or decreasing but for example if it is increasing then
it cannot decrease or vice versa in order to be deemed monotonic. This can be
represented mathematically as \(f(x) <= f(y) \forall x <= y\) or \(f(x) >= f(y) \forall z <=
y\). Functions that cleave to this mould are called monotonically increasing and
monotonically decreasing respectively. 
\subsection{Hyperplane Projection Method}
\label{sec:org1ed1a34}
Having covered a number of the prerequisites for using a hyperplane projection
method, the method itself can be explained. The version I looked at was
developed by Solodov and Svaiter and is called the Solodov and Svaiter
Hyperplane Projection Method (SSHPM) \cite{solodov1999new}. Figure 6.2 will be
referred to as a part of the explanation.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/SSHPM.png}
\caption{\label{fig:org3a8d3c8}
Solodov and Svaiter Hyperplane Projection Method}
\end{figure}

The curve in the figure describes the functional in the variational inequality
(VE) problem. This method uses the projection operator \(P_C[x] := arg min ||y -
x||\) where \(y \in C\). Suppose we have a point \(x^i\) which is the current approximation of
the solution to the VE problem involving the set \(C\) and the functional \(F\).
First we calculate a a projection point \(P_C[x^i - F(x^i)]\). The segment between
\(x^i\) and \(P_C[x^i - F(x^i)]\) is searched for a point \(z^i\), using a linesearch
method like the Armijo linesearch method \cite{armijo1966minimization}, such that
a hyperplane \(\delta H_i\) (using the definition of \(H_i\) as defined in figure 6.2)
strictly separates \(x^i\) from any solution \(x^*\) of the problem. The next
approximation to the solution \(x^{i+1}\) is calculated by projecting \(x^i\) onto the
intersection of the set \(C\) and the halfspace \(H^i\) that contains the solution
set using \(P_{C \cap H_i}\).

The benefit of this solution is that each iteration of the method only requires
two projections which makes it computationally efficient, the first to calculate
the hyperplane \(H_i\) and another onto the intersection \(C \cap H^i\) to find the next
iterate in finding the solution. Later on in the Implementation section, the
application of this method will be discussed in further detail.
\part{Implementation}
\label{sec:orgb4b71f9}
\chapter{Design}
\label{sec:orgc1b5932}
\section{Games vs Auctions}
\label{sec:orgb0f1019}
In the background section of this report both the concepts of Auctions and Game
Theory as both were considered as potential candidates for the management system
to match supply and demand in a nanogrid system. Ultimately however, a
non-cooperative game was chosen as the prime candidate for the smart grid in
this project. It is important to first consider the reasons as to why this
choice was made before explaining how the game was designed.

In the process of investigation of auctions and game theory, certain
similarities stood out between the two management systems. Ultimately all actors
within either of these systems are trying to maximise their utility, a scalar
value that is determined based on a number of key variables that each actor
considers pertinent to their operation. In the case of a model such as this one,
where a price value is involved, the utility of any given actor is usually
modelled as a balance between any profit that the unit could make versus some
kind of risk factor of selling too much at any one given time. In this regard,
the modelling of any actors within the grid would end up being the same on a
conceptual level and only the interactions between them would change based on
what kind of system was chosen.

As has been outlined in previous sections, one of the main criteria for the
nanogrid system, was that of minimal sharing of information between actors in
the grid. This was to decrease the size of packets exchanged between nodes in
the network as well as to hopefully decrease the number of packets sent between
each other in order to improve the efficiency of such a system such that it
might be practical for a real world scenario. Therefore the focus was on a
system that would fit this design. Every auction that was investigated as part
of this report had a crucial element of either all nodes being aware of the each
others' private information or at the very least the central node needed to have
all this information to hand. Therefore a non-cooperative game seemed more
appropriate based off this particular design. 
\section{System Design}
\label{sec:org1a0ff94}
In this section I will discuss a brief overview of the operation of the system
implemented in this project. Below in Figure 7.2 is a basic flowchart of a
single iteration of the operation of the system, followed by a brief summary of
each step. The summary below assumes that all the nodes within the network have
connected with one another already, although in my code submission there is an
extra step to ensure that the system process doesn't start until the user
decides that it should so that the system can be monitored on a step by step
basis. Figure 7.1 is a simple diagram of the connections between different
actors within the system.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/basic_network.png}
\caption{\label{fig:org946cf53}
Simple diagram to understand the connections between the different actors involved in the system in a given iteration}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/design.png}
\caption{\label{fig:orgfe24a0b}
Flow chart depicting the operation of the system in terms of the Central Power Station (CPS), Energy Consumers (ECs) and Energy Suppliers (ESs) in a single iteration}
\end{figure}

An iteration of the system is conducted to match supply and demand for in a
nanogrid situation for a given upcoming timeslot. Some kind of system where a
consumer can predict their energy usage for the next timeslot is presumed to be
in place. The suppliers of course know what their own supply of energy is as
well as having a caution variable \(c \in (0, 1)\). The caution value determines how
willing they are to sell larger amounts of energy, a low caution value
representing a willingness to sell more energy and a high value standing for a
more conservative supplier.

The operation begins with the Central Power Station (CPS) announcing a timeslot
to all consumers and all suppliers within the network. At the beginning the CPS
doesn't know who is a consumer and who is a supplier in order to accommodate the
situation where a consumer has proactively bought too much energy in
anticipation of needing it or has been instructed by some logic to sell excess
energy into the grid. Each Energy Consumer (EC) then notifies the CPS as to
whether it is in need of energy or whether it has energy to sell and if it's the
case of the former then it also sends how much energy it requires. Figure 7.1
shows the situation where ECs within the grid have already made it clear as to
whether they are a supplier or a consumer for this particular timeslot.

The CPS then simply sums the total demand and can begin the game. It sends the
total demand, the total amount of money it has available to give and the
number of suppliers within the system to each Energy Supplier (ES). The total
price is calculated naively by multiplying the current price per unit that is
offered by the central grid by the number of units of energy required by the
consumers within the nanogrid. A standard unit would be kWh. Each ES first
calculates how much energy it can be offered by dividing the total price by the
number of players. Each one then uses the SSHPM optimisation method to determine
an estimate for the energy it is willing to give to the CPS at that price and
sends that estimate to the CPS. The functional used as part of the SSHPM is the
utility function of each EC and the set of values being mapped over is a one
dimensional vector space that goes from zero to whatever the total energy of
each EC is.

The CPS then receives each ES's energy estimate. From this it is able to
estimate how willing each ES is to giving more or less energy. It cannot work
out the private store or the caution of each ES but rather understands the ratio
that exists between all the different players involved. The CPS then uses its
own utility function and the vector of energy estimates from each ES as the
inputs to a convex optimisation problem. A disciplined convex optimisation
method is employed \cite{grant2006disciplined} as any standard convex optimisation 
technique is all that is required and the Python solver CVXPY \cite{diamond2016cvxpy} was readily
available. A new vector of prices per ES is generated and each one is sent to
each ES. This is the actual price that each ES receives.

The ESs then play another game using their utility functions and the new price
that they have been offered by the CPS and try to find the actual amount of
energy that they are willing to give away using SSHPM. This energy is then sent
to the CPS. The CPS then sums the total of energy that has been provided at that
time. If this energy matches the total demand of the consumers in the nanogrid,
then the energy is simply supplied to those who need it, on a first come first
serve basis. However, if the supply does not reach the demand then the CPS buys
the extra power that is needed from the central power grid as seen in Figure
7.1. This system accepts the fact that it may not be able to supply all
consumers within the nanogrid using solely local sources that exist within its
own grid. Once the supply matches the demand, the power is then distributed as
before. The process then starts again ahead of the next timeslot to ensure that
everyone that needs power during that time is supplied.
\section{Game Design}
\label{sec:org59a4339}
First some of the key components of the game as well as a brief overview of how
it is conducted will be explained. Following that, the game itself will be
discussed in further detail. The game played between all of the ESs that are
trying to receive remuneration for the energy they are willing to offer is
played across two steps. First of all the ESs use their utility functions along
with a number of other important variables such as their energy capacity \(E_n\),
caution \$c\(_{\text{n}}\) and the current price offer \(p_n\) in order to determine their new
estimate for how much energy they are willing to offer to the CPS \(e_n\), where
\(n \in N\), N being the set of all ESs taking part in the nanogrid. Next they use
that energy estimate to calculate a slack variable \(\varepsilon_n\) which is a
variable indicating the amount of energy it is willing to offer without giving
up any private information. These slack variables are derived from the ES's
utility functions which will be discussed in the next section. The slack
variables are used by the CPS to determine Nash Equilibrium within the game,
namely this is when all of the slack variables are equal. Once this state of
equilibrium is reached, then the CPS asks for the energy offer from each of the
ESs.

When the hyperplane projection is initially calculated there is a small piece of
logic that determines what slack variable is sent to the CPS as well as what
energy should be offered. If the projection is equal to zero then \(\varepsilon_n = E_n -
2c_{n}e_{n} + p_n\). Otherwise the second part of the hyperplane projection method is
run, where the halfspace is determined and from that a new projection is worked
out. In this case the slack variable sent back to the CPS is \(\varepsilon_n = E_n - e_n +
p_n\). These slack variables are then sent to the CPS. If the slack variables are
all equal, as previously mentioned, then the game has reached the state of Nash
Equilibrium and the ESs are informed to end their iterations and they instead
send back the amount of energy they are offering. If the slack variables are not
equal then the CPS instructs the ESs to perform another iteration of the SSHPM.
\section{Utility Functions}
\label{sec:org5724f77}
\subsection{EC Utility Function}
\label{sec:orgae7c596}
Each EC has a utility function that is used as the functional in the the
hyperplane projection optimisation. The utility function in question takes into
account the energy that EC \(n\) has stored \(E_n\), the price being offered to it
\(p_n\), the caution value of that EC \(c_n\) and the energy that it is offering \(e_n\).
$$ U(e_n, E_n, p_n) = p_{n}e_{n} + (E_{n} - c_{n}e_{n})e_{n} $$ 
This utility function is based on the profit that the EC could get when it is
supplying energy, that is \(p_{n}e_{n}\). \((E_{n} - c_{n}e_{n})e_{n}\) represents
the loss that the EC incurs by giving away a certain amount of power. Ultimately
the system is trying to maximise the utilities of all ECs in the nanogrid, where
the sum of all offered energies is less than or equal to the energy deficiency
(demand) of the system for a given timeslot \(E_{def}\), that is $$\sum_n e_n <=
E_{def}$$. 

The utility function defined for the EC is the the crux of this project in order
to both structure the game itself and to determine the efficacy of the system.
The utility function is defined such that each EC is better utilised for each
timeslot but also does not expend too much electricity at one time unless the
incentive, namely the price, for it to do so is very high. This means that at a
later stage when there is perhaps a higher deficit, it can make more money in
the future as opposed to potentially being depleted of energy for the times of
high profit.
\subsection{CPS Utility Function}
\label{sec:orged7bac2}
The CPS has its own utility function that serves as the convex function for the
convex optimisation problem in trying to find appropriate prices for each of the
ESs that have submitted energy estimates for how much they are willing to offer.
The function is represented as a minimisation problem in terms of the energy
that each ES is offering \(e_n\), the price that the CPS would offer for that
energy \(p_n\) and two scalar values \(a_n\) and \(b_n\)  that account for the costs
associated with storing and transmitting the energy.

$$min_p L(p,e) = min_{p_{n}} \sum_n(e_{n}p_n^r + a_{n}p_{n} + b_n), subject to
\sum_n p_n = P, p_{min} <= p_n <= p_{max}$$

For each ES, the CPS is trying to find the value of \(p_n\) that will give the
smallest value. However all values of \(p_n\) must sum to be equal to the value of
\(P\), the total price that the CPS is willing to pay. As can be seen in this
model, the system doesn't pay any less for power overall, but rather
incentivises all suppliers of electricity to try to match the demand in
question. Another caveat of the minimisation problem is that \(p_n\) must be
between the values of \(p_{min}\) and \(p_{max}\). This simply means that there is a
minimum and a maximum value that the CPS is willing to pay for energy.
\chapter{Application}
\label{sec:org7f59efa}
\section{Python Twisted Framework}
\label{sec:org05598a2}
In the course of this project the Python Twisted Framework \cite{twistedpython}
was used in order to implement a network between the CPS and the ECs. The
Twisted Framework has a number of layers in order to abstract out the problem
for the user so that they only need care about their own application
\cite{kinder2005event}. It also has a number of inbuilt functions so that the
programmer does not have to care about things like sockets that are very tricky
and are far removed from the problem trying to be solved in this project.

Both the Client and the Server have two main layers where all the Twisted magic
happens, the Factory layer and the Protocol layer. Essentially the Factory layer
contains all of the persistent information of any given network actor and the
Protocol layer contains actions and information for every connection made by
that actor. In the code produced as part of this project, the factories of the
CPS and the ECs were mostly used to store the values of variables pertinent to
each of them such as the price vectors for the CPS and the energy storage for
each of the ECs.

The majority of the logic that controls both the CPS and ECs was contained
within separate Finite State Machine (FSM) files which were connected to their
respective Protocol files the FSM only changes state based on the inputs it
receives from any given connection. It was easiest to abstract the problem out
in this fashion for ease of reading and understanding of the code for both the
programmer and any potential readers. Each EC and the CPS is finally wrapped by
a simple run script that just sets up the factory from which everything else is
run. In each section below, the FSM of both the ECs and the CPS will be examined
as the system is conducted in the same fashion for both, where the protocol
calls a different function in the FSM depending on the state of the actor at
that time.
\section{Client (EC)}
\label{sec:org4b2e567}
\subsection{Idle State}
\label{sec:org12b4687}
The idle state is merely a state for in between operations of the system, where
no game is being played. In this project it was also used as an initial state
before the user decides to start the game. When a new game is started by the
CPS, it notifies each EC to move into the start state.
\subsection{Start State}
\label{sec:org7992622}
The start state is where the EC sends a message to the CPS to inform it as to
whether it is a supplier or a consumer for the upcoming timeslot. If it is a
consumer then it also sends the amount of energy that it requires at that time.
Also if an EC in the nanogrid requires no energy for the next timeslot, then it
simply puts itself back into the idle state, awaiting the next timeslot when it
might need or be able to supply energy. An EC moves to the Estimate 1 State if
it is a supplier and to the receive state if it is a consumer.
\subsection{Estimate 1 State}
\label{sec:orge8eb243}
This state is used for when the ESs are playing the game and making their first
estimate of how much energy they are willing to offer to the CPS. In this state,
if an ES is told to "End" its iterations then it moves to the second estimation
state (Estimate 2 State). Otherwise it uses the hyperplane projection method
solver (SSHPM Implementation) that was developed as part of this project and
sends a slack variable to the CPS, used in determining Nash Equilibrium for the
game. 
\subsection{Estimate 2 State}
\label{sec:orge7c25d9}
The Estimate 2 State is more or less the exact same as Estimate 1 State except
that when it receives the "End" message, it instead moves back to the idle
state, having successfully supplied energy to the CPS and having been
remunerated for that energy. If it doesn't receive the end message then it uses
SSHPM to calculate a new slack variable and continues playing the game.
\subsection{Receive State}
\label{sec:orgdc0df17}
The Receive State is the state for any consumers for the current timeslot. An EC
stays in this state until the operation of the system has been completed and the
energy is distributed to it accordingly. Once it receives this energy, it
returns to the Idle state in order to wait for the next timeslot.
\subsection{SSHPM Implementation}
\label{sec:orga4cd95b}
The SSHPM implementation caused the greatest amount of difficulty as part of
this final year project. The paper \cite{solodov1999new} details a complex and
dense mathematical algorithm that was difficult to grasp and to implement. The
functions with the SSHPM.py file follow the steps in the algorithm defined by
Solodov and Svaiter.
\section{Server (CPS)}
\label{sec:orga180704}
\subsection{Idle State}
\label{sec:org5f4592a}
The Idle State is used while the there is no game happening and the CPS is idle.
The CPS is then able to move into the start state when it wants to begin a game
immediately preceding a new timeslot. In this implementation it's also used on
start-up of the system so that the operation of the system doesn't begin until
every EC is connected to the CPS. Each connected EC is stored in a Python
dictionary with its relevant connection.
\subsection{Start State}
\label{sec:orgd84c351}
The Start state accepts incoming messages from each of the ECs about whether
they will be a consumer or a supplier for the current timeslot or if they will
be abstaining from the current round of operation. It stores each EC's role in
the upcoming game and doesn't move to the next state until every single EC in
the network has given an answer as to what their role shall be. The CPS then
naively calculates the demand by simply summing the values given by each of the
consumers and then moves to the Init State, 
\subsection{Init State}
\label{sec:org41525c0}
The Init State is used to allow the suppliers who will be taking part in the
game to start the game by providing them with the values that they need. Each EC
is sent the energy deficiency (\(E_{def}\)) for the current timeslot and price that
the CPS is willing to offer to each EC. The price is calculated by multiplying
\(E_{def}\) by the current price per unit of energy and dividing that by the
number of ESs in the system. The CPS then moves to the Game 1 State.
\subsection{Game 1 State}
\label{sec:org7006d55}
The Game 1 State is used for the first game that is played by the ECs that are
supplying energy for the current timeslot. When all connected ESs have responded
with their slack variables, the CPS runs a quick check as to whether or not the
slack variables are equal. If they are then it tells the ESs to finish their
iterations of SSHPM and to send the energy estimate that they used to calculate
the last slack variable that they sent and then the CPS moves to the
Optimisation State. If the slack variables are not all equal then the CPS tells
the ESs to continue playing the game.
\subsection{Optimisation State}
\label{sec:org5c3123a}
The Optimisation state first waits to receive the energy estimates from each ES
in the game of the current timeslot before beginning the convex optimisation. It
formulates the problem and then solves it using the CVXPY \cite{diamond2016cvxpy}
solver library. The new prices are then extracted from the solver and the CPS
sends the relevant price to each ES before moving to the Game 2 State.
\subsection{Game 2 State}
\label{sec:orga1d1a18}
The Game 2 State is more or less identical to the Game 1 State except that it is
concerned with managing the ESs who are trying to calculate the actual amount of
energy that they will give to the CPS as opposed to an estimate. In this state,
when the slack variables are equal, it similarly tells the ECs to stop the
iterations of their game and then it moves the CPS to the Distribute State.
\subsection{Distribute State}
\label{sec:org8c5feed}
The Distribute State first makes sure that all ESs have submitted the amount of
energy that they are going to provide to the CPS. It then sums these values and
compares that to \(E_{def}\) and if it the supplied energy is insufficient, then it
buys the extra energy needed from the central grid. It then disperses the energy
needed to each of the consumers within the current timeslot and moves into the
idle state, ready for the next game before the next timeslot.
\part{Conclusion}
\label{sec:org2ab86e8}
\chapter{Results}
\label{sec:orgcf6902a}
Ultimately the success of the system was unable to be determined due to
difficulties with the implementation of the hyperplane projection method.
Instead of converging on a value for the energy estimate, it instead approaches
zero for every instance but never reaches it, and therefore runs infinitely. In
order to solve for this, a number of lecturers within the school of computer
science were contacted for assistance and the author of the paper, Wayes Tushar,
was approached. However Mr Tushar was unavailable and unfortunately a proper
understanding of the mathematics involved in SSHPM was not reached and
consequently a correct code implementation could not be achieved.

However, a pen and paper comparison between the REFIT scheme and the proposed
scheme was calculated to demonstrate a potential scenario of operation in order
to compare the two systems. The slack variables were calculated on paper and
were hard-coded into the current system in order that the code can be run as
opposed to running indefinitely. The attempt at the correct solution is still
present but is currently commented out. These sections are flagged in the code.
This scenario was run between a single consumer and two suppliers. The consumer
sets \(Edef= 700\) and the two suppliers have \(E1 = 1100\) and \(E2 = 1000\). The
price per unit (kWh) is set at \(1.85\). When the proposed system is run with
these values the sum of utilities \(∑n U_n = 1069618.928\). Compared to the REFIT
scheme where the ratio between the capacities is used as a naive method of
deciding how much energy should be given by each EC, in a system where they
share private information. In this scenario, the sum of utilities \(∑n U_n =
1068167.8\).

Unfortunately, due to the lack of conversion on correct values by the system, no
further scenarios could be calculated as it is unclear as to what the values
that the optimisation methods would reach in instances where the supply does not
meet the demand. Optimisation techniques can often require several iterations
before converging on a correct value and therefore are not feasible to be worked
out on paper.
\chapter{Assessment}
\label{sec:org3d30589}
From the numerical results it can be easily seen that the proposed method in
this instance is superior to the REFIT scheme as the sum of utilities is greater
in the former approach. However the difference between the two utilities is
minimal so this system may not be the worth implementing in reality. A working
solution, however, would verify whether this statement is true or not.

Regardless, another equally important question to answer as part of this
project, is about the likeliness of such an system being implemented in the real
world. First of all, it must be noted that such a system could only be deployed
following advancements in the creation of suitable prediction methods for
predicting the amount of energy that a consumer will require within the next
timeslot. Secondly, the installation of such a smart grid would require a huge
overhaul of the current network if this system was focussed on immediately.
Rather, a more realistic approach would be to first introduce smart meters into
homes in conjunction with the current grid, like is in place in Italy as
discussed previously and to follow that with a REFIT scheme to incentivise the
installation and construction of local renewable energy sources as is in place
in Germany. At this point it would then be feasible to introduce a system such
as the one discussed in this report. The reason why a REFIT scheme would need to
precede a game theoretic solution is that on a human level, people would need
tangible and static amounts of money to ensure that they would see a return on
their investment whereas the game theoretic approach does not yield a concrete
and easy-to-grasp amount of money.
\chapter{Future Work and Continuations}
\label{sec:orgb7b732e}
There are a number of interesting ways in which this project could be continued,
that were realised during the course of the investigation of the field of smart
grids and in the particular area around which this project is based. These are
in two distinct categories: the former being ways in which this project could
have been extended had there been more time and the latter being ways in which
investigations could be made into pairing this project with other proposed smart
grid technologies. 

Originally there was the intention to eventually implement a prototype for the
supply and demand matching using a number of Raspberry Pis connected over a WiFi
network in order to analyse network latencies as well as to create a real,
tangible network and prove whether or not this system could be implemented on a
larger scale.

Another potential extension would be to create a hierarchy of CPSs in a larger
smart grid, where the CPS of a nanogrid in a house would then act as an EC
within say the community or neighbourhood. The CPS controlling that region would
then be an EC for a larger region, say a county or even an area code. However a
major change would need to take place in order to implement such a system. The
current system that was examined in this project, only ever tried to supply
energy less than or equal to the upcoming energy deficiency. This extension
however would require the game to be able to produce a surplus of electricity
for a single house at a given time period. If this was possible then a house
could then act as a supplier in the game within its own neighbourhood and
actually generate a further profit for that house. 

As mentioned previously in this report, as well as supply side management
systems, there are also plenty of papers concerned with demand side management.
Most of these papers were primarily concerned with driving down the price of
energy at any one given timeslot so it would be interesting to investigate
pairing such a system with the system in this paper in order to see whether the
low price generated is still enough to incentivise suppliers to give energy to
the CPS. If successful, such an amalgamation would help citizens who had such a
grid system set up in two different ways, first by driving down their costs and
then by allowing them to sell energy to further reduce their costs.

The final potential continuation of this project would be to pair any devices
that would solely be suppliers in a nanogrid such as wind turbines and solar
panels, with some form of prediction software relating to weather patterns
\cite{foley2012current}. This data could then be used to inform an EC's caution
value. For example if the EC was nearing capacity and it knew that it was going
to be generating enough electricity that it would be unable to store it, then it
could have a very low caution value. Conversely, low energy capacity and low
production in the future could could be used to inform a higher caution value.

\printbibliography
\appendix
\end{document}